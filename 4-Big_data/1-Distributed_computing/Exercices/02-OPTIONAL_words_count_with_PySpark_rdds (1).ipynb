{"cells":[{"cell_type":"markdown","source":["# Words count with PySpark RDDs\nIf you've ever heard of \"Hello, world!\" for web development, \"Word count\" is the actual equivalent for distributed computing.\n\nIn this notebook, we will setup a pipeline that will also us to count the words of a document in a distributed manner. For convenience, we will do this on a single small document, but what we do should be able to generalize to bigger documents that would not fit into the memory of a single machine."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"afcf7702-6c56-4b1d-80bf-73dc29548333"}}},{"cell_type":"code","source":["### BEGIN STRIP ###\nimport pyspark\n\nspark = (pyspark.sql.SparkSession.builder \\\n         .master('local') \\\n         .appName('Introduction to PySpark') \\\n         .config(\"spark.some.config.option\", \"some-value\") \\\n         .getOrCreate())\n\nsc = spark.sparkContext\n\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99dab8b1-deed-4a5f-9080-8a9ff467cc51"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# We need a S3 filepath\nS3_RESOURCE = 's3'\nSCHEME = 's3a'\n# TODO: assign a BUCKET_NAME and PREFIX\nBUCKET_NAME = ''\nPREFIX = ''\nFILENAME = 'purple_rain.txt'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2ecf16a-af0c-4715-b94f-6e1a21a989af"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# This is just a utility function\ndef get_s3_path(key, bucket_name=BUCKET_NAME, scheme=SCHEME):\n    return f\"{scheme}://{bucket_name}/{key}\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff1985dc-8f16-4352-a894-1dca1499baef"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["filepath = get_s3_path(FILENAME)\n### BEGIN STRIP ###\n# This is required for local work\n\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ab7a979a-7aec-4f00-9317-04637db8cfc0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# TODO: it already maps to lines... ???\n# TODO: load the filepath to a Spark RDD using `.textFile(...)` from a SparkContext\n### BEGIN STRIP ###\nfrom pathlib import Path\npath = Path(\"FileStore\", \"shared_uploads\", \"thibaudchevrier@gmail.com\", \"purple_rain.txt\")\npurple_rain_rdd = sc.textFile(str(path))\n\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7bb8c7c-7b21-40f4-8df1-49967623c6da"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# TODO: print out `text_file`\n### BEGIN STRIP ###\n\nprint(purple_rain_rdd)\n\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9bb196d9-0315-4058-834c-e120c3e8df3d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">FileStore/shared_uploads/thibaudchevrier@gmail.com/purple_rain.txt MapPartitionsRDD[167] at textFile at &lt;unknown&gt;:0\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">FileStore/shared_uploads/thibaudchevrier@gmail.com/purple_rain.txt MapPartitionsRDD[167] at textFile at &lt;unknown&gt;:0\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["That doesn't tell us much, how would you do to see the first 3 elements of this RDD?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4691569-f9ce-4011-9b0d-4ac83afbb67d"}}},{"cell_type":"code","source":["# TODO: take the first 3 elements of the RDD `text_file`\n### BEGIN STRIP ###\n\npurple_rain_rdd.take(3)\n\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18cf5fc3-aa88-43e1-bfb4-51ca8043c9ee"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[87]: [&#39;I never meant to cause you any sorrow&#39;,\n &#39;I never meant to cause you any pain&#39;,\n &#39;I only wanted one time to see you laughing&#39;]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[87]: [&#39;I never meant to cause you any sorrow&#39;,\n &#39;I never meant to cause you any pain&#39;,\n &#39;I only wanted one time to see you laughing&#39;]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["This is a list of sentences, what we want is a list of tokens."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82d5981a-3540-42a9-b170-3232bfe20d58"}}},{"cell_type":"code","source":["### BEGIN STRIP ###\n\ntokenized_text = purple_rain_rdd.map(lambda line: line.split(\" \"))\ntokenized_text.take(3)\n\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de644952-7338-41cf-a54c-110fe37ad7a0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[88]: [[&#39;I&#39;, &#39;never&#39;, &#39;meant&#39;, &#39;to&#39;, &#39;cause&#39;, &#39;you&#39;, &#39;any&#39;, &#39;sorrow&#39;],\n [&#39;I&#39;, &#39;never&#39;, &#39;meant&#39;, &#39;to&#39;, &#39;cause&#39;, &#39;you&#39;, &#39;any&#39;, &#39;pain&#39;],\n [&#39;I&#39;, &#39;only&#39;, &#39;wanted&#39;, &#39;one&#39;, &#39;time&#39;, &#39;to&#39;, &#39;see&#39;, &#39;you&#39;, &#39;laughing&#39;]]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[88]: [[&#39;I&#39;, &#39;never&#39;, &#39;meant&#39;, &#39;to&#39;, &#39;cause&#39;, &#39;you&#39;, &#39;any&#39;, &#39;sorrow&#39;],\n [&#39;I&#39;, &#39;never&#39;, &#39;meant&#39;, &#39;to&#39;, &#39;cause&#39;, &#39;you&#39;, &#39;any&#39;, &#39;pain&#39;],\n [&#39;I&#39;, &#39;only&#39;, &#39;wanted&#39;, &#39;one&#39;, &#39;time&#39;, &#39;to&#39;, &#39;see&#39;, &#39;you&#39;, &#39;laughing&#39;]]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["That's not exactly what we wanted... We wanted a list of tokens, we got a.. **list of list of tokens**.  \nThat's because, in this case, we need a special version of `.map()` called `flatMap`: it will flatten the list of list of tokens into a list of tokens.\n\nLet's try it out: we take the same expression as the previous one, but replace `.map()` with `.flatMap()` and call the resulting variable `tokens`.\n\n---\n💡 It usually takes time to understand the notion of `.flatMap` and flattening in general, like `.map()`, these are concepts from the functionnal programming world. Unless you come from such background, it probably **won't be easy to grasp these concepts the first time to encouter them**.\n\n**Let's keep our eyes on the ball: our goal today is not to understand the specifics of these, but to develop a broader understanding of how Spark works.**\n\n---"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"255dc39a-b961-41b4-9030-7ab463b7352f"}}},{"cell_type":"code","source":["# TODO: copy/paste the previous cell, and:\n# - replace `.map(...) with `.flatMap(...)`\n# - rename the variable `tokenized_text` to `tokens`\n### BEGIN STRIP ###\n\ntokens = purple_rain_rdd.flatMap(lambda line: line.split(\" \"))\n\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42386e95-8c70-4a7e-a2ed-52fef93a856f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# TODO: Use this cell to play with `tokens`, take different amounts of it, or collect it.\n### BEGIN STRIP ###\n\ntokens.take(10)\n\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"35cce9fb-5d06-472b-9dda-6dba27a086a2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[90]: [&#39;I&#39;, &#39;never&#39;, &#39;meant&#39;, &#39;to&#39;, &#39;cause&#39;, &#39;you&#39;, &#39;any&#39;, &#39;sorrow&#39;, &#39;I&#39;, &#39;never&#39;]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[90]: [&#39;I&#39;, &#39;never&#39;, &#39;meant&#39;, &#39;to&#39;, &#39;cause&#39;, &#39;you&#39;, &#39;any&#39;, &#39;sorrow&#39;, &#39;I&#39;, &#39;never&#39;]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now that we have our list of words (well, **not exactly a list of words, it is still a RDD**), we can start counting things.\n\nIn order to do that, we need to map each word to an initial count, so instead of having:\n```\n['I',\n 'never',\n 'meant',\n ...,\n 'I',\n 'never',\n ...]\n```\nWe would like our list to look like this:\n```\n[('I', 1),\n ('never', 1),\n ('meant', 1),\n ...,\n ('I', 1),\n ('never', 1),\n ...]\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eaea6503-6946-4133-a459-4d70125ff177"}}},{"cell_type":"code","source":["# TODO: Write a function `token_to_tuple` that takes:\n#       - a token as input (a string)\n#       - and returns (token, 1) (a tuple) \n### BEGIN STRIP ###\n\ndef token_to_tuple(token):\n  return (token, 1)\n  \n\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d3639ff-2594-4829-8652-93ae8ce1c14e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# TODO: map `tokens` to your new function `token_to_tuple`: `partial_count`\n### BEGIN STRIP ###\npartial_count = tokens.map(lambda token: token_to_tuple(token))\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a063bf3-b6cf-4b26-b5b4-26c26c1c6bb1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# TODO: take the first 10 elements of `partial_count`\n### BEGIN STRIP ###\npartial_count.take(10)\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"760dbefd-e230-4f9c-a33f-72e1c8a4e91b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[93]: [(&#39;I&#39;, 1),\n (&#39;never&#39;, 1),\n (&#39;meant&#39;, 1),\n (&#39;to&#39;, 1),\n (&#39;cause&#39;, 1),\n (&#39;you&#39;, 1),\n (&#39;any&#39;, 1),\n (&#39;sorrow&#39;, 1),\n (&#39;I&#39;, 1),\n (&#39;never&#39;, 1)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[93]: [(&#39;I&#39;, 1),\n (&#39;never&#39;, 1),\n (&#39;meant&#39;, 1),\n (&#39;to&#39;, 1),\n (&#39;cause&#39;, 1),\n (&#39;you&#39;, 1),\n (&#39;any&#39;, 1),\n (&#39;sorrow&#39;, 1),\n (&#39;I&#39;, 1),\n (&#39;never&#39;, 1)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Good job!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3187096c-332e-4b87-8ed8-7ecb04d878e5"}}},{"cell_type":"markdown","source":["Beware, now comes the hard-part... We need to reduce this..\n\nDon't forget, when we start using DataFrame, because these are higher level abstractions, it will take care of most of these steps for us.\n\nWhat we want, is take the tuple with similar keys, like `('never', 1)` and `('never', 1)` and count them, so in the end we have `('never', 2)` (or more than 2 if there are more occurence of 'never').\n\nThese kind of tuples are called **key-value pairs**, and while most Spark operations work on RDDs containing any type of objects, a few special operations are only available on RDDs of key-value pairs. You can read more about it [in the documentation](https://spark.apache.org/docs/latest/rdd-programming-guide.html#working-with-key-value-pairs).\n\nAmong these operations are `.groupByKey(...)` and `.reduceByKey(...)`: the latter has better performances, but the former is easier to understand so we will start with this one."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69965478-5369-41ac-b962-15b53aa6b0b7"}}},{"cell_type":"markdown","source":["### groupByKey"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c410b422-622e-47af-8a88-9e59d0b8c0a4"}}},{"cell_type":"code","source":["# TODO: call `.groupByKey(...)` on partial_count: grouped_by_key\n#       and take the first 3 elements\n### BEGIN STRIP ###\ngrouped_by_key = partial_count.groupByKey()\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f0b4bd1-c449-48bf-a70e-407b5b493ccd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# TODO: take the first 3 elements of `grouped_by_key`\n### BEGIN STRIP ###\ngrouped_by_key.take(3)\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ccd9e0d9-8f18-48fd-a5d2-21352fc9faaa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[95]: [(&#39;never&#39;, &lt;pyspark.resultiterable.ResultIterable at 0x7f691cd13610&gt;),\n (&#39;cause&#39;, &lt;pyspark.resultiterable.ResultIterable at 0x7f691cd13790&gt;),\n (&#39;pain&#39;, &lt;pyspark.resultiterable.ResultIterable at 0x7f691cd15e50&gt;)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[95]: [(&#39;never&#39;, &lt;pyspark.resultiterable.ResultIterable at 0x7f691cd13610&gt;),\n (&#39;cause&#39;, &lt;pyspark.resultiterable.ResultIterable at 0x7f691cd13790&gt;),\n (&#39;pain&#39;, &lt;pyspark.resultiterable.ResultIterable at 0x7f691cd15e50&gt;)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["What's this: `<pyspark.resultiterable.ResultIterable at 0x10bc0c2d0>` ?\n\nYou don't have to worry about the details, but one thing has to attract your attention: `Iterable`, this seems to suggest those objects are iterable, an iterable in Python is something that you can iterate on: basicall something that you can call `for` on, like a list, or a string, etc..\n\n```\nfor letter in 'Spark':\n    print(e)\n> S\n> p\n> a\n> r\n> k\n```\n\nEach element of `grouped_by_key` is a tuple, and inside a tuple there is an iterable we can iterate over.\n\nWe will first try with the first element."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"37611bfc-b07b-421c-80d7-a4ee6e6b0824"}}},{"cell_type":"code","source":["# TODO: take the first element of `grouped_by_key`: first_item\n#       and print out its type\n# WARNING: the type should be a tuple, not a list\n### BEGIN STRIP ###\ntype(grouped_by_key.take(1)[0])\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b26cbebb-2d87-4f4b-8b22-1ab61aaaa8bf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[96]: tuple</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[96]: tuple</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We'd like a way to print these items, for example, such that 'never' would look like this:\n```\n'never': [1, 1, 1, 1]\n```\n\nWe will write a function that does this, take an item as a tuple of (`str`, `ResultIterable`), and print out:\n```\nITEM_NAME: OCCURENCES_AS_A_LIST\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"422d80c2-a7df-4606-b03f-0d89c7504f52"}}},{"cell_type":"code","source":["# TODO: define a way to print our item\n### BEGIN STRIP ###\ndef print_item(token):\n  print(token[0], [value for value in token[1]])\n\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7dbc1d4-69ce-49d5-9d91-fda23109c9b9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# TODO: take the first 10 items from grouped_by_key and then iterate over them\n#       then, inside the loop, use the function `print_item(...)` on each item\n### BEGIN STRIP ###\nfor token in grouped_by_key.take(10):\n  print_item(token)\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"02cde29b-c379-4a29-8a5a-8b00d894ca7a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">never [1, 1, 1, 1]\ncause [1, 1]\npain [1]\nonly [1, 1, 1, 1, 1, 1, 1]\nin [1, 1]\nrain [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nPurple [1, 1, 1, 1, 1, 1, 1, 1, 1]\nrain, [1, 1, 1, 1, 1, 1, 1, 1, 1]\nbathing [1]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">never [1, 1, 1, 1]\ncause [1, 1]\npain [1]\nonly [1, 1, 1, 1, 1, 1, 1]\nin [1, 1]\nrain [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nPurple [1, 1, 1, 1, 1, 1, 1, 1, 1]\nrain, [1, 1, 1, 1, 1, 1, 1, 1, 1]\nbathing [1]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Next step might be challenging.\n\nWhen you take the first 10 elements of `grouped_by_key`, it returns a list of `Tuple[str, ResultIterable]`.  \nWhat we want instead is a list of `Tuple[str, int]` where the second element is the total number of occurence for the fist element.\n\nNOTE: you might wanna try to first return a list of `Tuple[str, list]`.\n\nYou should be able to do all this using only list comprehensions."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3bad65c4-9716-41d0-84bc-57b18e4053b1"}}},{"cell_type":"code","source":["# TODO: follow previous instructions\n### BEGIN STRIP ###\ngrouped_by_key.map(lambda token: (token[0], sum([value for value in token[1]]))).collect()\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2af11fce-df0f-4eac-a83d-d6faab2fecf2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[99]: [(&#39;never&#39;, 4),\n (&#39;cause&#39;, 2),\n (&#39;pain&#39;, 1),\n (&#39;only&#39;, 7),\n (&#39;in&#39;, 2),\n (&#39;rain&#39;, 14),\n (&#39;&#39;, 10),\n (&#39;Purple&#39;, 9),\n (&#39;rain,&#39;, 9),\n (&#39;bathing&#39;, 1),\n (&#39;kind&#39;, 1),\n (&#39;of&#39;, 1),\n (&#39;steal&#39;, 1),\n (&#34;It&#39;s&#34;, 2),\n (&#39;end&#39;, 1),\n (&#39;underneath&#39;, 1),\n (&#39;know&#39;, 2),\n (&#39;are&#39;, 1),\n (&#39;we&#39;, 1),\n (&#39;out&#39;, 1),\n (&#39;something&#39;, 1),\n (&#39;new&#39;, 1),\n (&#39;That&#39;, 1),\n (&#39;means&#39;, 1),\n (&#39;say&#39;, 1),\n (&#39;leader&#39;, 1),\n (&#39;But&#39;, 1),\n (&#39;make&#39;, 1),\n (&#39;mind&#39;, 1),\n (&#39;think&#39;, 1),\n (&#39;close&#39;, 1),\n (&#39;And&#39;, 1),\n (&#39;let&#39;, 1),\n (&#39;guide&#39;, 1),\n (&#39;singing&#39;, 1),\n (&#34;C&#39;mon,&#34;, 1),\n (&#39;I&#39;, 14),\n (&#39;meant&#39;, 2),\n (&#39;to&#39;, 13),\n (&#39;you&#39;, 14),\n (&#39;any&#39;, 2),\n (&#39;sorrow&#39;, 1),\n (&#39;wanted&#39;, 3),\n (&#39;one&#39;, 1),\n (&#39;time&#39;, 2),\n (&#39;see&#39;, 6),\n (&#39;laughing&#39;, 2),\n (&#39;want&#39;, 6),\n (&#39;the&#39;, 5),\n (&#39;purple&#39;, 14),\n (&#39;be&#39;, 2),\n (&#39;your&#39;, 3),\n (&#39;weekend&#39;, 1),\n (&#39;lover&#39;, 1),\n (&#39;some&#39;, 1),\n (&#39;friend&#39;, 1),\n (&#39;Baby,&#39;, 1),\n (&#39;could&#39;, 1),\n (&#39;from&#39;, 1),\n (&#39;another&#39;, 1),\n (&#39;such&#39;, 1),\n (&#39;a&#39;, 2),\n (&#39;shame&#39;, 1),\n (&#39;our&#39;, 1),\n (&#39;friendship&#39;, 1),\n (&#39;had&#39;, 1),\n (&#39;Honey&#39;, 1),\n (&#39;know,&#39;, 2),\n (&#39;times&#39;, 1),\n (&#39;changing&#39;, 1),\n (&#39;all&#39;, 1),\n (&#39;reach&#39;, 1),\n (&#39;for&#39;, 1),\n (&#39;too&#39;, 1),\n (&#39;You&#39;, 1),\n (&#34;can&#39;t&#34;, 1),\n (&#39;seem&#39;, 1),\n (&#39;up&#39;, 2),\n (&#39;better&#39;, 1),\n (&#39;it&#39;, 1),\n (&#39;me&#39;, 1),\n (&#39;If&#39;, 1),\n (&#39;what&#39;, 1),\n (&#34;I&#39;m&#34;, 1),\n (&#39;about&#39;, 1),\n (&#39;here&#39;, 1),\n (&#39;raise&#39;, 1),\n (&#39;hand&#39;, 1),\n (&#39;you,&#39;, 1),\n (&#39;In&#39;, 1)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[99]: [(&#39;never&#39;, 4),\n (&#39;cause&#39;, 2),\n (&#39;pain&#39;, 1),\n (&#39;only&#39;, 7),\n (&#39;in&#39;, 2),\n (&#39;rain&#39;, 14),\n (&#39;&#39;, 10),\n (&#39;Purple&#39;, 9),\n (&#39;rain,&#39;, 9),\n (&#39;bathing&#39;, 1),\n (&#39;kind&#39;, 1),\n (&#39;of&#39;, 1),\n (&#39;steal&#39;, 1),\n (&#34;It&#39;s&#34;, 2),\n (&#39;end&#39;, 1),\n (&#39;underneath&#39;, 1),\n (&#39;know&#39;, 2),\n (&#39;are&#39;, 1),\n (&#39;we&#39;, 1),\n (&#39;out&#39;, 1),\n (&#39;something&#39;, 1),\n (&#39;new&#39;, 1),\n (&#39;That&#39;, 1),\n (&#39;means&#39;, 1),\n (&#39;say&#39;, 1),\n (&#39;leader&#39;, 1),\n (&#39;But&#39;, 1),\n (&#39;make&#39;, 1),\n (&#39;mind&#39;, 1),\n (&#39;think&#39;, 1),\n (&#39;close&#39;, 1),\n (&#39;And&#39;, 1),\n (&#39;let&#39;, 1),\n (&#39;guide&#39;, 1),\n (&#39;singing&#39;, 1),\n (&#34;C&#39;mon,&#34;, 1),\n (&#39;I&#39;, 14),\n (&#39;meant&#39;, 2),\n (&#39;to&#39;, 13),\n (&#39;you&#39;, 14),\n (&#39;any&#39;, 2),\n (&#39;sorrow&#39;, 1),\n (&#39;wanted&#39;, 3),\n (&#39;one&#39;, 1),\n (&#39;time&#39;, 2),\n (&#39;see&#39;, 6),\n (&#39;laughing&#39;, 2),\n (&#39;want&#39;, 6),\n (&#39;the&#39;, 5),\n (&#39;purple&#39;, 14),\n (&#39;be&#39;, 2),\n (&#39;your&#39;, 3),\n (&#39;weekend&#39;, 1),\n (&#39;lover&#39;, 1),\n (&#39;some&#39;, 1),\n (&#39;friend&#39;, 1),\n (&#39;Baby,&#39;, 1),\n (&#39;could&#39;, 1),\n (&#39;from&#39;, 1),\n (&#39;another&#39;, 1),\n (&#39;such&#39;, 1),\n (&#39;a&#39;, 2),\n (&#39;shame&#39;, 1),\n (&#39;our&#39;, 1),\n (&#39;friendship&#39;, 1),\n (&#39;had&#39;, 1),\n (&#39;Honey&#39;, 1),\n (&#39;know,&#39;, 2),\n (&#39;times&#39;, 1),\n (&#39;changing&#39;, 1),\n (&#39;all&#39;, 1),\n (&#39;reach&#39;, 1),\n (&#39;for&#39;, 1),\n (&#39;too&#39;, 1),\n (&#39;You&#39;, 1),\n (&#34;can&#39;t&#34;, 1),\n (&#39;seem&#39;, 1),\n (&#39;up&#39;, 2),\n (&#39;better&#39;, 1),\n (&#39;it&#39;, 1),\n (&#39;me&#39;, 1),\n (&#39;If&#39;, 1),\n (&#39;what&#39;, 1),\n (&#34;I&#39;m&#34;, 1),\n (&#39;about&#39;, 1),\n (&#39;here&#39;, 1),\n (&#39;raise&#39;, 1),\n (&#39;hand&#39;, 1),\n (&#39;you,&#39;, 1),\n (&#39;In&#39;, 1)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["As you've seen this can be done using standard list comprehension.  \nIf you're curious, even though Python is not a purely functional language, you can write this in a functional fashion and achieve the same result.\n\n_Please note this would look obviouly more elegant in a purely functional language.  \nAnd I put it in there only to introduce you to another programming paradigm if you've mostly encountered imperative programming before. This little introduction is helpful because Spark is based on Scala, which, although not being a purely functional language, provides support for many functional programming features._"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a61b0675-2e24-4310-aff9-6076ab26e029"}}},{"cell_type":"code","source":["# Don't try at home ;)\n\nfrom functools import reduce\n\nlist(map(lambda t: (t[0], reduce(lambda a, b: a + b, t[1])),\n         grouped_by_key.take(10)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9bd40be8-91ec-4359-a0dc-da0432dcf39a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[100]: [(&#39;never&#39;, 4),\n (&#39;cause&#39;, 2),\n (&#39;pain&#39;, 1),\n (&#39;only&#39;, 7),\n (&#39;in&#39;, 2),\n (&#39;rain&#39;, 14),\n (&#39;&#39;, 10),\n (&#39;Purple&#39;, 9),\n (&#39;rain,&#39;, 9),\n (&#39;bathing&#39;, 1)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[100]: [(&#39;never&#39;, 4),\n (&#39;cause&#39;, 2),\n (&#39;pain&#39;, 1),\n (&#39;only&#39;, 7),\n (&#39;in&#39;, 2),\n (&#39;rain&#39;, 14),\n (&#39;&#39;, 10),\n (&#39;Purple&#39;, 9),\n (&#39;rain,&#39;, 9),\n (&#39;bathing&#39;, 1)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["That would work, but that's using regular Python, hence we're not profiting from Spark's distributed computing capabilities, which means:\n- the computation would be much slower on big datasets\n- if the datasets is too big to be stored on the memory of our machine our program would crash\n\nThat's exactly what `.reduceByKey(...)` will help us to solve. It's usage is a bit similar to `.groupByKey(...)` but it takes a function as a parameter, this function should tell Spark how to aggregate 2 items, in our case, that the value of each tuple, for example :\nLet's say we have a group:\n```\n('dog', 1), ('dog', 1)\n```\nwe want a formula applied on values that will give us the end result, e.g. \"how many dogs\".\nIn our case, that's a simple sum:\n```\ndef reduce_function(value_1, value_2):\n    return value_1 + value_2\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3c7c8bd0-5194-4b12-ab22-a917d0732895"}}},{"cell_type":"code","source":["# TODO: write our reduce function: reduce_function\n#       which takes 2 values and return their sum\n# NOTE: name this parameters `a` and `b`\n### BEGIN STRIP ###\ndef reduce_function(a, b):\n    return a + b\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b54523a-ed4b-4910-a07f-08c03cf9deb3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We're now ready to reduce. You will pass your function as parameter to `.reduceByKey(...)`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41fa835a-a107-43af-bca8-fe34d21d5adf"}}},{"cell_type":"code","source":["# TODO: call `.reduceByKey(...) on `partial_count`: `reduced`\n### BEGIN STRIP ###\nreduced = partial_count.reduceByKey(reduce_function)\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"995c3da3-0841-4c98-80a2-b01968cf8294"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# TODO: take the 10 first values\n### BEGIN STRIP ###\nreduced.take(10)\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d1f5681b-54b7-4b86-8652-6ca131b25fb3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[103]: [(&#39;never&#39;, 4),\n (&#39;cause&#39;, 2),\n (&#39;pain&#39;, 1),\n (&#39;only&#39;, 7),\n (&#39;in&#39;, 2),\n (&#39;rain&#39;, 14),\n (&#39;&#39;, 10),\n (&#39;Purple&#39;, 9),\n (&#39;rain,&#39;, 9),\n (&#39;bathing&#39;, 1)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[103]: [(&#39;never&#39;, 4),\n (&#39;cause&#39;, 2),\n (&#39;pain&#39;, 1),\n (&#39;only&#39;, 7),\n (&#39;in&#39;, 2),\n (&#39;rain&#39;, 14),\n (&#39;&#39;, 10),\n (&#39;Purple&#39;, 9),\n (&#39;rain,&#39;, 9),\n (&#39;bathing&#39;, 1)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**[TODO]: reword this part**\n\nWow! Good job. We're almost there... 😅\nWe've got a list of tuples, where the key is the token, and the value is its count within the text, but.. \n**they're not ordered...** which is inconvenient if we want to have the 10 most popular tokens within the text.\n\nWe will use `.sortBy(...)`, but before we do, let's have a refresher on sorting with Python.\n\nFor example, how would you sort this grocery list by the number of items?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4cd0d8d8-2fdf-46d4-9d2c-b163ad6b5bc5"}}},{"cell_type":"code","source":["fruits = [('banana', 3), ('orange', 5), ('pineapple', 2)]\nfruits"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8b98355e-5140-41a8-b123-43d19841e235"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[104]: [(&#39;banana&#39;, 3), (&#39;orange&#39;, 5), (&#39;pineapple&#39;, 2)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[104]: [(&#39;banana&#39;, 3), (&#39;orange&#39;, 5), (&#39;pineapple&#39;, 2)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["`sorted(fruits)` won't work because by default sorting on tuple take the first element, in our case, it would sort alphabetically on the name of the fruits."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0aba35f0-051e-4c1b-80b1-6b7ce7f21308"}}},{"cell_type":"code","source":["sorted(fruits)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"827e1ad9-298b-40e1-9d14-999d212735b9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[105]: [(&#39;banana&#39;, 3), (&#39;orange&#39;, 5), (&#39;pineapple&#39;, 2)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[105]: [(&#39;banana&#39;, 3), (&#39;orange&#39;, 5), (&#39;pineapple&#39;, 2)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We can force the `key` parameter to sort on the second item of each tuple."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"daeccffd-72f5-49be-baf9-f2f74699aafc"}}},{"cell_type":"code","source":["sorted(fruits, key=lambda x: x[1])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc67f96a-c3d2-4579-9a36-5502f4d3be1d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[106]: [(&#39;pineapple&#39;, 2), (&#39;banana&#39;, 3), (&#39;orange&#39;, 5)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[106]: [(&#39;pineapple&#39;, 2), (&#39;banana&#39;, 3), (&#39;orange&#39;, 5)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now, we will do the same on our rdd. Just like `key` in Python's `sorted`, PySpark's `.sortBy(...)` can take a function as a parameter."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"30bd7e96-2121-4c52-9157-6acd205404ae"}}},{"cell_type":"code","source":["# TODO: use `.sortBy(...)` on `reduced`: sorted_counts\n### BEGIN STRIP ###\nsorted_counts = reduced.sortBy(lambda t: t[1])\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"23b9aacf-72d3-47e1-bea7-072c3ddab924"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# TODO: take the 10 first values of `sorted_counts`\n### BEGIN STRIP ###\nsorted_counts.take(10)\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5bfc748a-8519-41a5-87c6-23be23aa686a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[108]: [(&#39;pain&#39;, 1),\n (&#39;bathing&#39;, 1),\n (&#39;kind&#39;, 1),\n (&#39;of&#39;, 1),\n (&#39;steal&#39;, 1),\n (&#39;end&#39;, 1),\n (&#39;underneath&#39;, 1),\n (&#39;are&#39;, 1),\n (&#39;we&#39;, 1),\n (&#39;out&#39;, 1)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[108]: [(&#39;pain&#39;, 1),\n (&#39;bathing&#39;, 1),\n (&#39;kind&#39;, 1),\n (&#39;of&#39;, 1),\n (&#39;steal&#39;, 1),\n (&#39;end&#39;, 1),\n (&#39;underneath&#39;, 1),\n (&#39;are&#39;, 1),\n (&#39;we&#39;, 1),\n (&#39;out&#39;, 1)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["What do you think?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71747bf9-c626-41c3-9c31-8cce22d09a3a"}}},{"cell_type":"markdown","source":["It seems sorted, but in **ascending order**..  \nIf we wanted to do this in Python, we could just set the `reverse` argument to `True` when calling `sorted(...)`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0d7f327-6f92-4d6a-840c-1682981ca76e"}}},{"cell_type":"code","source":["sorted(fruits, key=lambda x: x[1], reverse=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb98ddc9-73b3-4537-afa0-c5e4c9505c61"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[109]: [(&#39;orange&#39;, 5), (&#39;banana&#39;, 3), (&#39;pineapple&#39;, 2)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[109]: [(&#39;orange&#39;, 5), (&#39;banana&#39;, 3), (&#39;pineapple&#39;, 2)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We can't do this with Spark's RDDs. What we can do instead is **take the opposite value and order by it**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7125ed92-0143-4efb-92d8-e3bc993b2a05"}}},{"cell_type":"code","source":["# TODO: use `.sortBy(...)` on `reduced`, but with a descending sort: desc_sorted_counts\n### BEGIN STRIP ###\ndesc_sorted_counts = reduced.sortBy(lambda t: t[1], False)\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1d8fd6f6-d032-42d5-9f74-d5804d0dabc5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# TODO: take the 10 first values of `desc_sorted_counts`\n### BEGIN STRIP ###\ndesc_sorted_counts.take(10)\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d5452b7-c650-44b8-98ee-172ebe02ce21"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[111]: [(&#39;rain&#39;, 14),\n (&#39;I&#39;, 14),\n (&#39;you&#39;, 14),\n (&#39;purple&#39;, 14),\n (&#39;to&#39;, 13),\n (&#39;&#39;, 10),\n (&#39;Purple&#39;, 9),\n (&#39;rain,&#39;, 9),\n (&#39;only&#39;, 7),\n (&#39;see&#39;, 6)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[111]: [(&#39;rain&#39;, 14),\n (&#39;I&#39;, 14),\n (&#39;you&#39;, 14),\n (&#39;purple&#39;, 14),\n (&#39;to&#39;, 13),\n (&#39;&#39;, 10),\n (&#39;Purple&#39;, 9),\n (&#39;rain,&#39;, 9),\n (&#39;only&#39;, 7),\n (&#39;see&#39;, 6)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Finally, what's the most common word in our document?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4029e36a-f22f-44c9-b714-e318d00a5135"}}},{"cell_type":"markdown","source":["### **Bonus**: putting everything together\n\nWe will create a function `count_words` that will do everything we did previously, but this time in one swell swoop, we won't use intermediary variables.\n\nThe function will:\n- take a filepath as argument\n- load the content of this filepath into a Spark RDD\n- `flatMap(...)` each line of this RDD into tokens by splitting on the ' ' string\n- `.map(...)` each token to `(token, 1)` so this can be then reduced\n- by calling `.reduceByKey(...)` with a function that sums the values\n- and then sort the results with `.sortBy(...)` using the proper function to sort in descending order\n- and return an RDD\n\n---\n⚠️ Make sure your function returns a RDD\n\n---"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec6452c1-10c0-4abf-bdd3-1249ed5c4f3f"}}},{"cell_type":"code","source":["def count_words(filepath):\n    # TODO: implement the content of the function\n    # \n    # NOTE: you can remove `pass`\n    # it's just here to avoid the cell crashing while the\n    # content of the function is empty\n    ### BEGIN STRIP ###\n    text_rdd = sc.textFile(str(filepath))\n    return text_rdd.flatMap(lambda line: [(t, 1) for t in line.split(\" \")]).reduceByKey(lambda a, b: a+b).sortBy(lambda t: t[1], False)\n    ### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6320c9a-b201-4d10-b751-43027c487d5e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# TODO: use `count_words` on `filepath` and check its type\n### BEGIN STRIP ###\nres = count_words(path)\nprint(res.collect())\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0236d4e-c6ba-4e58-987b-f715f41ce237"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[(&#39;rain&#39;, 14), (&#39;I&#39;, 14), (&#39;you&#39;, 14), (&#39;purple&#39;, 14), (&#39;to&#39;, 13), (&#39;&#39;, 10), (&#39;Purple&#39;, 9), (&#39;rain,&#39;, 9), (&#39;only&#39;, 7), (&#39;see&#39;, 6), (&#39;want&#39;, 6), (&#39;the&#39;, 5), (&#39;never&#39;, 4), (&#39;wanted&#39;, 3), (&#39;your&#39;, 3), (&#39;cause&#39;, 2), (&#39;in&#39;, 2), (&#34;It&#39;s&#34;, 2), (&#39;know&#39;, 2), (&#39;meant&#39;, 2), (&#39;any&#39;, 2), (&#39;time&#39;, 2), (&#39;laughing&#39;, 2), (&#39;be&#39;, 2), (&#39;a&#39;, 2), (&#39;know,&#39;, 2), (&#39;up&#39;, 2), (&#39;pain&#39;, 1), (&#39;bathing&#39;, 1), (&#39;kind&#39;, 1), (&#39;of&#39;, 1), (&#39;steal&#39;, 1), (&#39;end&#39;, 1), (&#39;underneath&#39;, 1), (&#39;are&#39;, 1), (&#39;we&#39;, 1), (&#39;out&#39;, 1), (&#39;something&#39;, 1), (&#39;new&#39;, 1), (&#39;That&#39;, 1), (&#39;means&#39;, 1), (&#39;say&#39;, 1), (&#39;leader&#39;, 1), (&#39;But&#39;, 1), (&#39;make&#39;, 1), (&#39;mind&#39;, 1), (&#39;think&#39;, 1), (&#39;close&#39;, 1), (&#39;And&#39;, 1), (&#39;let&#39;, 1), (&#39;guide&#39;, 1), (&#39;singing&#39;, 1), (&#34;C&#39;mon,&#34;, 1), (&#39;sorrow&#39;, 1), (&#39;one&#39;, 1), (&#39;weekend&#39;, 1), (&#39;lover&#39;, 1), (&#39;some&#39;, 1), (&#39;friend&#39;, 1), (&#39;Baby,&#39;, 1), (&#39;could&#39;, 1), (&#39;from&#39;, 1), (&#39;another&#39;, 1), (&#39;such&#39;, 1), (&#39;shame&#39;, 1), (&#39;our&#39;, 1), (&#39;friendship&#39;, 1), (&#39;had&#39;, 1), (&#39;Honey&#39;, 1), (&#39;times&#39;, 1), (&#39;changing&#39;, 1), (&#39;all&#39;, 1), (&#39;reach&#39;, 1), (&#39;for&#39;, 1), (&#39;too&#39;, 1), (&#39;You&#39;, 1), (&#34;can&#39;t&#34;, 1), (&#39;seem&#39;, 1), (&#39;better&#39;, 1), (&#39;it&#39;, 1), (&#39;me&#39;, 1), (&#39;If&#39;, 1), (&#39;what&#39;, 1), (&#34;I&#39;m&#34;, 1), (&#39;about&#39;, 1), (&#39;here&#39;, 1), (&#39;raise&#39;, 1), (&#39;hand&#39;, 1), (&#39;you,&#39;, 1), (&#39;In&#39;, 1)]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[(&#39;rain&#39;, 14), (&#39;I&#39;, 14), (&#39;you&#39;, 14), (&#39;purple&#39;, 14), (&#39;to&#39;, 13), (&#39;&#39;, 10), (&#39;Purple&#39;, 9), (&#39;rain,&#39;, 9), (&#39;only&#39;, 7), (&#39;see&#39;, 6), (&#39;want&#39;, 6), (&#39;the&#39;, 5), (&#39;never&#39;, 4), (&#39;wanted&#39;, 3), (&#39;your&#39;, 3), (&#39;cause&#39;, 2), (&#39;in&#39;, 2), (&#34;It&#39;s&#34;, 2), (&#39;know&#39;, 2), (&#39;meant&#39;, 2), (&#39;any&#39;, 2), (&#39;time&#39;, 2), (&#39;laughing&#39;, 2), (&#39;be&#39;, 2), (&#39;a&#39;, 2), (&#39;know,&#39;, 2), (&#39;up&#39;, 2), (&#39;pain&#39;, 1), (&#39;bathing&#39;, 1), (&#39;kind&#39;, 1), (&#39;of&#39;, 1), (&#39;steal&#39;, 1), (&#39;end&#39;, 1), (&#39;underneath&#39;, 1), (&#39;are&#39;, 1), (&#39;we&#39;, 1), (&#39;out&#39;, 1), (&#39;something&#39;, 1), (&#39;new&#39;, 1), (&#39;That&#39;, 1), (&#39;means&#39;, 1), (&#39;say&#39;, 1), (&#39;leader&#39;, 1), (&#39;But&#39;, 1), (&#39;make&#39;, 1), (&#39;mind&#39;, 1), (&#39;think&#39;, 1), (&#39;close&#39;, 1), (&#39;And&#39;, 1), (&#39;let&#39;, 1), (&#39;guide&#39;, 1), (&#39;singing&#39;, 1), (&#34;C&#39;mon,&#34;, 1), (&#39;sorrow&#39;, 1), (&#39;one&#39;, 1), (&#39;weekend&#39;, 1), (&#39;lover&#39;, 1), (&#39;some&#39;, 1), (&#39;friend&#39;, 1), (&#39;Baby,&#39;, 1), (&#39;could&#39;, 1), (&#39;from&#39;, 1), (&#39;another&#39;, 1), (&#39;such&#39;, 1), (&#39;shame&#39;, 1), (&#39;our&#39;, 1), (&#39;friendship&#39;, 1), (&#39;had&#39;, 1), (&#39;Honey&#39;, 1), (&#39;times&#39;, 1), (&#39;changing&#39;, 1), (&#39;all&#39;, 1), (&#39;reach&#39;, 1), (&#39;for&#39;, 1), (&#39;too&#39;, 1), (&#39;You&#39;, 1), (&#34;can&#39;t&#34;, 1), (&#39;seem&#39;, 1), (&#39;better&#39;, 1), (&#39;it&#39;, 1), (&#39;me&#39;, 1), (&#39;If&#39;, 1), (&#39;what&#39;, 1), (&#34;I&#39;m&#34;, 1), (&#39;about&#39;, 1), (&#39;here&#39;, 1), (&#39;raise&#39;, 1), (&#39;hand&#39;, 1), (&#39;you,&#39;, 1), (&#39;In&#39;, 1)]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["It should be a `pyspark.rdd.PipelineRDD`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62e28750-a9d5-4eea-9f0b-1fba411715e0"}}},{"cell_type":"code","source":["# TODO: finally, take the 10 first elements of your RDD\n### BEGIN STRIP ###\nres.take(10)\n### END STRIP ###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0964f5c2-c888-4547-9859-6d641ec6b320"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[114]: [(&#39;rain&#39;, 14),\n (&#39;I&#39;, 14),\n (&#39;you&#39;, 14),\n (&#39;purple&#39;, 14),\n (&#39;to&#39;, 13),\n (&#39;&#39;, 10),\n (&#39;Purple&#39;, 9),\n (&#39;rain,&#39;, 9),\n (&#39;only&#39;, 7),\n (&#39;see&#39;, 6)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[114]: [(&#39;rain&#39;, 14),\n (&#39;I&#39;, 14),\n (&#39;you&#39;, 14),\n (&#39;purple&#39;, 14),\n (&#39;to&#39;, 13),\n (&#39;&#39;, 10),\n (&#39;Purple&#39;, 9),\n (&#39;rain,&#39;, 9),\n (&#39;only&#39;, 7),\n (&#39;see&#39;, 6)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["That's it, you've done it!\n\nYou've created a Spark job, the next step would be to neatly package this into a Python executable and submit it to a Spark Cluster for batch or stream execution, but this is beyond the content of this course."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"465b596a-2315-4659-927d-d32e8f9a4fc9"}}},{"cell_type":"markdown","source":["## Going further\n\nWe used a toy dataset, we suggest you try with a bigger one."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"834dda0d-6f62-402a-bb38-a5ed4dc12481"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"02-OPTIONAL_words_count_with_PySpark_rdds","dashboards":[],"language":"python","widgets":{},"notebookOrigID":1146077705634089}},"nbformat":4,"nbformat_minor":0}
