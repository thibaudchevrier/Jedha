{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and logging our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-1.15.0-py3-none-any.whl (14.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.2 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from mlflow) (1.19.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from mlflow) (1.1.3)\n",
      "Collecting gunicorn; platform_system != \"Windows\"\n",
      "  Downloading gunicorn-20.1.0.tar.gz (370 kB)\n",
      "\u001b[K     |████████████████████████████████| 370 kB 68.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.8/site-packages (from mlflow) (3.12.4)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from mlflow) (5.3.1)\n",
      "Collecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.18.1.tar.gz (21 kB)\n",
      "Collecting sqlparse>=0.3.1\n",
      "  Downloading sqlparse-0.4.1-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.8/site-packages (from mlflow) (7.1.2)\n",
      "Collecting docker>=4.0.0\n",
      "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 69.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting querystring-parser\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting Flask\n",
      "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 4.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: requests>=2.17.3 in /opt/conda/lib/python3.8/site-packages (from mlflow) (2.24.0)\n",
      "Collecting alembic<=1.4.1\n",
      "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 42.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gitpython>=2.1.0\n",
      "  Downloading GitPython-3.1.14-py3-none-any.whl (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 48.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sqlalchemy in /opt/conda/lib/python3.8/site-packages (from mlflow) (1.3.19)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.8/site-packages (from mlflow) (1.6.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.8/site-packages (from mlflow) (2020.1)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.14.3.tar.gz (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 3.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->mlflow) (2.8.1)\n",
      "Requirement already satisfied: setuptools>=3.0 in /opt/conda/lib/python3.8/site-packages (from gunicorn; platform_system != \"Windows\"->mlflow) (49.6.0.post20201009)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.8/site-packages (from protobuf>=3.6.0->mlflow) (1.15.0)\n",
      "Requirement already satisfied: prometheus_client in /opt/conda/lib/python3.8/site-packages (from prometheus-flask-exporter->mlflow) (0.8.0)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.58.0-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 9.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Werkzeug>=0.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 68.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Jinja2>=2.10.1 in /opt/conda/lib/python3.8/site-packages (from Flask->mlflow) (2.11.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (2.10)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.8/site-packages (from alembic<=1.4.1->mlflow) (1.1.3)\n",
      "Requirement already satisfied: python-editor>=0.3 in /opt/conda/lib/python3.8/site-packages (from alembic<=1.4.1->mlflow) (1.0.4)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tabulate>=0.7.7\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from Jinja2>=2.10.1->Flask->mlflow) (1.1.1)\n",
      "Collecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: gunicorn, prometheus-flask-exporter, alembic, databricks-cli\n",
      "  Building wheel for gunicorn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gunicorn: filename=gunicorn-20.1.0-py3-none-any.whl size=78918 sha256=f5a71c0b2f8a17e47e7503305a7f6d9a2d54d4ae311b4ade8348ece30d6c4384\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/21/4b/32/9be8daf8a4d73da26e4dba66c47c9b4b7d838a6b372981a3ed\n",
      "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.1-py3-none-any.whl size=17157 sha256=970da111ed59d3624b4e1ccb57209b50af31597e0e95b8303c15a37ceb26b2f1\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/12/1a/8d/0c016e06370d07f82def661b6cb7d91d4e6b4ff7f2982e9f2c\n",
      "  Building wheel for alembic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=27cc6ee59ae7b7a5b24903a4a0771e63b78350d6896386589e0e9c26aec567a2\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/9d/de/6d/ca8d461ec29e010b1267d7353d0b058819770f7680bb9360e4\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.14.3-py3-none-any.whl size=100556 sha256=ed2d91ef3d0597888ccb33b01b8184c50c33a9defc4e89f7c2f4070782ab79fe\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e9/f3/dc/eeff77dbc147629fa716741fc216520abbc0e15ce4b876706f\n",
      "Successfully built gunicorn prometheus-flask-exporter alembic databricks-cli\n",
      "Installing collected packages: gunicorn, itsdangerous, Werkzeug, Flask, prometheus-flask-exporter, sqlparse, websocket-client, docker, querystring-parser, alembic, smmap, gitdb, gitpython, tabulate, databricks-cli, mlflow\n",
      "  Attempting uninstall: alembic\n",
      "    Found existing installation: alembic 1.4.3\n",
      "    Uninstalling alembic-1.4.3:\n",
      "      Successfully uninstalled alembic-1.4.3\n",
      "Successfully installed Flask-1.1.2 Werkzeug-1.0.1 alembic-1.4.1 databricks-cli-0.14.3 docker-5.0.0 gitdb-4.0.7 gitpython-3.1.14 gunicorn-20.1.0 itsdangerous-1.1.0 mlflow-1.15.0 prometheus-flask-exporter-0.18.1 querystring-parser-1.2.4 smmap-4.0.0 sqlparse-0.4.1 tabulate-0.8.9 websocket-client-0.58.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = pd.DataFrame(data = iris[\"data\"], columns= iris[\"feature_names\"])\n",
    "y = pd.DataFrame(data = iris[\"target\"], columns=[\"target\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression model\n",
      "Accuracy: 0.9473684210526315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    # Specified Parameters \n",
    "    c = 0.5\n",
    "\n",
    "    # Instanciate and fit the model \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train.values, y_train.values)\n",
    "\n",
    "    # Store metrics \n",
    "    predicted_qualities = lr.predict(X_test.values)\n",
    "    accuracy = lr.score(X_test.values, y_test.values)\n",
    "\n",
    "    # Print results \n",
    "    print(\"LogisticRegression model\")\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "\n",
    "    # Log Metric \n",
    "    mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "\n",
    "    # Log Param\n",
    "    mlflow.log_param(\"C\", c)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying our model to Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = \"iris\"\n",
    "\n",
    "# Region where you want your model to be deployed\n",
    "region = \"eu-west-3\"\n",
    "\n",
    "# You can change the instance type\n",
    "instance_type = \"ml.t2.medium\"\n",
    "\n",
    "# Get it from Mlflow\n",
    "run_id = \"\"\n",
    "model_uri = \"runs:/\" + run_id + \"/model\"\n",
    "\n",
    "# Put your AWS Role ARN\n",
    "execution_role = \"\"\n",
    "\n",
    "# Put the image URI took from AWS ECR\n",
    "image_ecr_url = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SageMaker app \n",
    "import mlflow.sagemaker as mfs\n",
    "\n",
    "mfs.deploy(\n",
    "    app_name=app_name,\n",
    "    model_uri=model_uri,\n",
    "    image_url=image_ecr_url,\n",
    "    region_name=region,\n",
    "    mode=\"replace\",\n",
    "    execution_role_arn=execution_role,\n",
    "    instance_type=instance_type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format input for API \n",
    "input_json = X_test.to_json(orient=\"split\")\n",
    "input_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the API endpoint\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "def query_endpoint(app_name, input_json):\n",
    "    # Instanciate a client in order to access Sagemaker\n",
    "    client = boto3.session.Session().client(\"sagemaker-runtime\", region)\n",
    "    # Call our Iris endpoint\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=app_name,\n",
    "        Body=input_json,\n",
    "        ContentType='application/json; format=pandas-split',\n",
    "    )\n",
    "    # We get the answer\n",
    "    preds = response['Body'].read().decode(\"ascii\")\n",
    "    preds = json.loads(preds)\n",
    "    print(\"Received response: {}\".format(preds))\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the input by posting it to the deployed model\n",
    "prediction1 = query_endpoint(app_name=app_name, input_json=input_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete app \n",
    "import mlflow.sagemaker as mfs\n",
    "\n",
    "# Specify the archive=False option to delete any SageMaker models and configurations\n",
    "# associated with the specified application\n",
    "mfs.delete(app_name=app_name, region_name=region, archive=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
