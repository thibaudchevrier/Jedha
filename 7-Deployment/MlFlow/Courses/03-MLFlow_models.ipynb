{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow Models \n",
    "\n",
    "<img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/mlflow-models.png\" width=600>\n",
    "\n",
    "## What you will learn in this course \n",
    "\n",
    "This is the fun part of Mlflow: deploy your model. In this course, you will learn: \n",
    "\n",
    "* What is MLFlow models\n",
    "* Log a model to MLFlow tracking\n",
    "* Serve an ML model locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is MLFlow models? ğŸ¤”ğŸ¤”\n",
    "\n",
    "The goal of MLFlow models is to provide a standard format for your Machine Learning models. This is especially useful when you want to deploy them later on any platform your company uses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log your MLFlow model â²ï¸â²ï¸\n",
    "\n",
    "If you want to be able to format your model, you will need to log it into MLFlow Tracking. This is actually very easy to do. Let's take the following example from the latest lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "53            5.5          2.3           4.0          1.3\n",
       "99            5.7          2.8           4.1          1.3\n",
       "34            4.9          3.1           1.5          0.2\n",
       "137           6.4          3.1           5.5          1.8\n",
       "136           6.3          3.4           5.6          2.4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Seperate into features and target variable\n",
    "X = pd.DataFrame(data = iris[\"data\"], columns= [\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"])\n",
    "y = pd.DataFrame(data = iris[\"target\"], columns=[\"target\"])\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Visualisation \n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To log a model, you have to determine which library you are using to train your model. In our case, it's going to be `sklearn`. Therefore, we are going to log our model the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression model\n",
      "Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Load model to Mlflow tracking \n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Specified Parameters \n",
    "    c = 0.5\n",
    "\n",
    "    # Instanciate and fit the model \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train.values, y_train.values)\n",
    "\n",
    "    # Store metrics \n",
    "    predicted_qualities = lr.predict(X_test.values)\n",
    "    accuracy = lr.score(X_test.values, y_test.values)\n",
    "\n",
    "    # Print results \n",
    "    print(\"LogisticRegression model\")\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "\n",
    "    # Log Metric \n",
    "    mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "\n",
    "    # Log Param\n",
    "    mlflow.log_param(\"C\", c)\n",
    "\n",
    "    # Log model \n",
    "    mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can visualize your model in MLFlow UI. You should also see your project folder with new files. It should be organize the following way:\n",
    "\n",
    "```shell\n",
    "â”œâ”€â”€ mlruns\n",
    "â”‚Â Â  â””â”€â”€ 0\n",
    "â”‚Â Â      â”œâ”€â”€ 0a2b502f674949b4acb8dfce6549a7fb\n",
    "â”‚Â Â      â”‚Â Â  â”œâ”€â”€ artifacts\n",
    "â”‚Â Â      â”‚Â Â  â”‚Â Â  â””â”€â”€ model\n",
    "â”‚Â Â      â”‚Â Â  â”‚Â Â      â”œâ”€â”€ MLmodel        â† New\n",
    "â”‚Â Â      â”‚Â Â  â”‚Â Â      â”œâ”€â”€ conda.yaml     â† New too\n",
    "â”‚Â Â      â”‚Â Â  â”‚Â Â      â””â”€â”€ model.pkl      â† New too two\n",
    "â”‚Â Â      â”‚Â Â  â”œâ”€â”€ meta.yaml\n",
    "â”‚Â Â      â”‚Â Â  â”œâ”€â”€ metrics\n",
    "â”‚Â Â      â”‚Â Â  â”‚Â Â  â””â”€â”€ Accuracy\n",
    "â”‚Â Â      â”‚Â Â  â”œâ”€â”€ params\n",
    "â”‚Â Â      â”‚Â Â  â”‚Â Â  â””â”€â”€ C\n",
    "â”‚Â Â      â”‚Â Â  â””â”€â”€ tags\n",
    "â”‚Â Â      â”‚Â Â      â”œâ”€â”€ mlflow.log-model.history\n",
    "â”‚Â Â      â”‚Â Â      â”œâ”€â”€ mlflow.source.name\n",
    "â”‚Â Â      â”‚Â Â      â”œâ”€â”€ mlflow.source.type\n",
    "â”‚Â Â      â”‚Â Â      â””â”€â”€ mlflow.user\n",
    "â”‚Â Â      â””â”€â”€ meta.yaml\n",
    "â””â”€â”€ train.ipynb\n",
    "```\n",
    "\n",
    "We will talk about the structure of this in the MLFlow Project part of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We logged an `sklearn` model but you have a lot more to your disposal! \n",
    "\n",
    "<ul>\n",
    "<li><p><a class=\"reference external\" href=\"https://github.com/mlflow/mlflow/tree/master/examples/gluon\">Gluon</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://github.com/mlflow/mlflow/tree/master/examples/h2o\">H2O</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://github.com/mlflow/mlflow/tree/master/examples/keras\">Keras</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://github.com/mlflow/mlflow/tree/master/examples/prophet\">Prophet</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://github.com/mlflow/mlflow/tree/master/examples/pytorch\">PyTorch</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://github.com/mlflow/mlflow/tree/master/examples/xgboost\">XGBoost</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://github.com/mlflow/mlflow/tree/master/examples/lightgbm\">LightGBM</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://github.com/mlflow/mlflow/tree/master/examples/r_wine\">Glmnet (R)</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://github.com/mlflow/mlflow/tree/master/examples/spacy\">SpaCy</a></p></li>\n",
    "<li><p>scikit-learn</p>\n",
    "<ul>\n",
    "<li><p><a class=\"reference external\" href=\"https://github.com/mlflow/mlflow/tree/master/examples/sklearn_elasticnet_diabetes\">Diabetes example</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://github.com/mlflow/mlflow/tree/master/examples/sklearn_elasticnet_wine\">Elastic Net example</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://github.com/mlflow/mlflow/tree/master/examples/sklearn_logistic_regression\">Logistic Regression example</a></p></li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><p>TensorFlow</p>\n",
    "<ul>\n",
    "<li><p><a class=\"reference external\" href=\"https://github.com/mlflow/mlflow/tree/master/examples/tensorflow/tf1\">TensorFlow 1.X</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://github.com/mlflow/mlflow/tree/master/examples/tensorflow/tf2\">TensorFlow 2.X</a></p></li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>\n",
    "</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serve your model \n",
    "\n",
    "### Create a local API\n",
    "\n",
    "Now that our model is logged and packaged, we can serve it as an API by doing:\n",
    "\n",
    "```shell\n",
    "$ mlflow models serve -m runs:/RUN_ID/model\n",
    "```\n",
    "\n",
    "For example: `mlflow models serve -m runs:/7be31e1452f4423e81a64f1bfcd2d371/model -p 1234`.\n",
    "\n",
    "If `mlflow ui` is still running on port 5000 (default port) it is important to serve your model on a different port (e.g. 1234).\n",
    "\n",
    "### Call the API\n",
    "\n",
    "To call your API, you will need to format your input data as `json` with `split` orientation. Check an example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"columns\":[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"],\"index\":[134,67,8,32,0,73,4,113,1,85,97,145,83,37,146,117,84,131,135,107,127,129,143,40,49,118,98,93,10,149,81,61,108,142,42,26,54,92],\"data\":[[6.1,2.6,5.6,1.4],[5.8,2.7,4.1,1.0],[4.4,2.9,1.4,0.2],[5.2,4.1,1.5,0.1],[5.1,3.5,1.4,0.2],[6.1,2.8,4.7,1.2],[5.0,3.6,1.4,0.2],[5.7,2.5,5.0,2.0],[4.9,3.0,1.4,0.2],[6.0,3.4,4.5,1.6],[6.2,2.9,4.3,1.3],[6.7,3.0,5.2,2.3],[6.0,2.7,5.1,1.6],[4.9,3.6,1.4,0.1],[6.3,2.5,5.0,1.9],[7.7,3.8,6.7,2.2],[5.4,3.0,4.5,1.5],[7.9,3.8,6.4,2.0],[7.7,3.0,6.1,2.3],[7.3,2.9,6.3,1.8],[6.1,3.0,4.9,1.8],[7.2,3.0,5.8,1.6],[6.8,3.2,5.9,2.3],[5.0,3.5,1.3,0.3],[5.0,3.3,1.4,0.2],[7.7,2.6,6.9,2.3],[5.1,2.5,3.0,1.1],[5.0,2.3,3.3,1.0],[5.4,3.7,1.5,0.2],[5.9,3.0,5.1,1.8],[5.5,2.4,3.7,1.0],[5.9,3.0,4.2,1.5],[6.7,2.5,5.8,1.8],[5.8,2.7,5.1,1.9],[4.4,3.2,1.3,0.2],[5.0,3.4,1.6,0.4],[6.5,2.8,4.6,1.5],[5.8,2.6,4.0,1.2]]}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.to_json(orient=\"split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now requests your model as an API. For example, try something like this in your terminal:  \n",
    "\n",
    "```shell \n",
    "$ curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"],\"data\":[[2.1, 1.5, 5.4, 4.2]]}' http://localhost:1234/invocations\n",
    "```\n",
    "\n",
    "If your are running on a Windows OS, you will have to use only double quotes and espace nested double quotes with anti slash as Windows command prompt does not support single quotes:\n",
    "\n",
    "```shell\n",
    "$ curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data \"{\\\"columns\\\":[\\\"sepal_length\\\",\\\"sepal_width\\\",\\\"petal_length\\\",\\\"petal_width\\\"],\\\"data\\\":[[2.1, 1.5, 5.4, 4.2]]}\" http://kubernetes.docker.internal:1234/invocations\n",
    "```\n",
    "\n",
    "You will get results just like this:\n",
    "\n",
    "```shell\n",
    "[2]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ•º Amazing! We have log our model and it is now ready to make predictions on demand in just few lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources \n",
    "\n",
    "* <a href=\"https://www.youtube.com/watch?v=859OxXrt_TI\" target=\"_blank\">MLflow: An Open Platform to Simplify the Machine Learning Lifecycle</a>\n",
    "* <a href=\"https://mlflow.org/docs/latest/tutorials-and-examples/index.html\" target=\"_blank\">Tutorials & Example</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
