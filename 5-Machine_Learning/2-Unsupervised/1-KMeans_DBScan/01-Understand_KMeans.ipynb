{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means\n",
    "\n",
    "## What you will learn in this course üßêüßê\n",
    "\n",
    "This course is designed to teach you a very popular Unsupervised Machine Learning algorithm called the **K-Means**. It allows you to classify the observations without making any assumptions about the distribution of the data and can be very fast. In this course, you will learn:\n",
    "\n",
    "* How K-Means algorithm works\n",
    "* How to initialize K using Elbow Method and Silhouette \n",
    "* What are the main advantages and flaws of K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised VS Unsupervised Reminder üéóÔ∏èüéóÔ∏è\n",
    "\n",
    "Contrary to Supervised Machine Learning, Unsupervised Learning corresponds to situations in which **we do not have a target variable** that we are trying to predict, but we hypothesize that the data we have can be compared within groups.\n",
    "\n",
    "\n",
    "\n",
    "![Supervised VS Unsupervised Graph](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Unsupervised_VS_supervised.png)\n",
    "\n",
    "The figure above illustrates the difference between:\n",
    "\n",
    "* Supervised learning on the left, where **crosses are known to be different from diamonds and we try to build a model to separate them**\n",
    "\n",
    "* Unsupervised learning on the right, where data is not labelled but can be separated by other methods: three coherent groups appear in the figure.\n",
    "\n",
    "Another diagram to explain the difference between the two types of Machine Learning is with datasets. \n",
    "\n",
    "![Supervised VS Unsupervised](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Unsupervised_VS_Supervised_target_no_target.png)\n",
    "\n",
    "On the left we are using $X_{1}$ and $X_{2}$ as training features to predict $Y$ whereas on the right, we don't have any $Y$, we simply want to find underlying structure within $X_{1}$ and $X_{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"640\"\n",
       "            height=\"360\"\n",
       "            src=\"https://player.vimeo.com/video/481705898?frameborder=0&allow=autoplay%3B+fullscreen\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f88c19c36d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\n",
    "    \"https://player.vimeo.com/video/481705898\",\n",
    "    width=\"640\" ,\n",
    "    height=\"360\",\n",
    "    frameborder=\"0\",\n",
    "    allow=\"autoplay; fullscreen\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usecases üé≠\n",
    "\n",
    "Let's talk about usecases. \n",
    "\n",
    "If we put ourselves in a marketing director's shoes of an e-commerce site, we have a database that refers customers where we know: \n",
    "\n",
    "*  The contents of their shopping carts üõí\n",
    "*  Their frequency of visits üë©‚Äçüë©‚Äçüë¶\n",
    "*  And many other information about them directly and their behavior on the site üëç\n",
    "\n",
    "The marketing director will often try to bring these customers together in research groups to better understand the issues that lead some individuals to adopt certain types of behaviour rather than others. ü¶ú\n",
    "\n",
    "For example, one may wish to identify who are parents, students, high income earners, lower income households, etc. \n",
    "\n",
    "However, the marketing manager does not have a database in which this information is entered in a variable, so he will have to classify customers without being able to rely on a target variable.\n",
    "\n",
    "üëã This is where **Unsupervised Machine Learning** comes in.üëã\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "\n",
    "**K-Means** method is a partitioning technique that separates observations into $K$ groups, where each observation is considered to belong to the group where the mean is the closest according to a given distance.\n",
    "\n",
    "K-Means algorithm is very popular because it is easy to implement üëç. Moreover, it can be applied to all types of data as long as one can define a function that gives the distance between two observations üòéüòé\n",
    "\n",
    "Let's now introduce K-means algorithm, and then we will discuss its main features, advantages and disadvantages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"640\"\n",
       "            height=\"360\"\n",
       "            src=\"https://player.vimeo.com/video/481702777?frameborder=0&allow=autoplay%3B+fullscreen\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f88c19e50d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\n",
    "    \"https://player.vimeo.com/video/481702777\",\n",
    "    width=\"640\" ,\n",
    "    height=\"360\",\n",
    "    frameborder=\"0\",\n",
    "    allow=\"autoplay; fullscreen\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Features\n",
    "\n",
    "According to the algorithm we have just exposed, we can notice several characteristics of K-means.\n",
    "\n",
    "* We must set $K$ in advance üëé But there are some methods that we can use to figure out the optimal number ü§ó which we will cover in the next section. \n",
    "\n",
    "* Clusters have to be <a href=\"https://projecteuclid.org/download/pdfview_1/euclid.ejs/1444828331\" target=\"_blank\">convex</a> and <a href=\"https://en.wikipedia.org/wiki/Isotropy\" target=\"_blank\">Isotropic</a>. If you don't want to bother clicking on the link, it simply means that your clusters should have a relatively rounded shape and data points shouldn't be too far from each other. \n",
    " \n",
    "* K-Means uses <a href=\"https://en.wikipedia.org/wiki/Euclidean_distance\" target=\"_blank\">Eucledian Distance</a> to create clusters. Although that is why this makes the algorithm easy to implement, Euclidian distances tend to be inflated when you are dealing with high dimensional data (meaning lots of features with high values). If you want to learn more about the different types of distances in mathematics, check out our appendix. \n",
    "\n",
    "* As $K$ is iniatilized at random, the algorithm can converge to a local minimum. In `sklearn`, the way to alleviate this problem is to initialize $K$ using `k-means++` which makes sure that each cluster centers are far from each other. üí™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to select $K$ üôâ\n",
    "\n",
    "Since we need to set $K$ in advance with K-Means, how to we know how many is optimal? Well there are two methods that you can use: \n",
    "\n",
    "1. Elbow üí™\n",
    "2. Silhouette üë•\n",
    "\n",
    "While both methods try to figure out how \"well your data is divided\", they come with two opposite approaches. \n",
    "\n",
    "üí™üí™ Elbow method is trying to see **whether each data points from a cluster is close from each other**. \n",
    "\n",
    "üë•üë• Silhouette is trying to figure out **how far are each cluster from each other** (and therefore how meaningful they are). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"640\"\n",
       "            height=\"360\"\n",
       "            src=\"https://player.vimeo.com/video/481698566?frameborder=0&allow=autoplay%3B+fullscreen\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f88c19e5ac0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\n",
    "    \"https://player.vimeo.com/video/481698566\",\n",
    "    width=\"640\" ,\n",
    "    height=\"360\",\n",
    "    frameborder=\"0\",\n",
    "    allow=\"autoplay; fullscreen\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means summary ‚úÖ\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "      <th>\n",
    "         Advantages\n",
    "      </th>\n",
    "      <th>\n",
    "         Flaws\n",
    "      </th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>\n",
    "         Very easy to set up.\n",
    "      </td>\n",
    "      <td>\n",
    "         If the two characters are identical we add 0 to the distance\n",
    "      </td>\n",
    "   </tr>\n",
    "\n",
    "   <tr>\n",
    "      <td>\n",
    "         Fast.\n",
    "      </td>\n",
    "      <td>\n",
    "         The result depends on the initialization of centroids, which affects the stability of the results (two different centroid initialization do not necessarily lead to the same partition).\n",
    "      </td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "      <td>\n",
    "         Applicable to very large volumes of data and for datasets with a large number of     variables.\n",
    "      </td>\n",
    "      <td>\n",
    "         Classes are constructed from points that do not exist in the observations.\n",
    "      </td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPENDIX - Types of distance in Machine Learning \n",
    "\n",
    "   \n",
    "### Manhattan Distance (also called L1)\n",
    "\n",
    "It corresponds to the distance traveled on each axis to go from a point $x$ to a point $y$. Its mathematical formula is:\n",
    "\n",
    "$$d_{1}(x,y)=\\sum_{i=1}^{p}|x_i - y_i|$$\n",
    "\n",
    "Where $x$ and $y$ are two observations containing $p$ quantitative variables (qualitative variables should also be transformed into quantitative variables).\n",
    "\n",
    "In the following figure, three visualizations of the Manhattan distance:\n",
    "\n",
    "<img alt=\"\" src=\"https://drive.google.com/uc?export=view&id=1t3lXO3TNikj61yptEdnGDORfD7j107rT\">\n",
    "\n",
    "This distance is useful for very large spaces, where it allows faster convergence of algorithms. In addition, this distance is less sensitive than others to outliers.\n",
    "\n",
    "## Euclidean (also called L2)\n",
    "\n",
    "The Euclidean distance is the most widely used distance in general, it is the distance as the crow flies.\n",
    "\n",
    "<img alt=\"Euclidean\" src=\"https://drive.google.com/uc?export=view&id=1GQVDa0-SmkAxdgr6pHn0Z4HiIozLfLk2\">\n",
    "\n",
    "This is the most widely used distance in practice, as it offers a good compromise between managing short and long distances.\n",
    "\n",
    "\n",
    "The following figure shows an illustration of the Euclidean distance in 3 dimensions:\n",
    "\n",
    "<img alt=\"\" src=\"https://drive.google.com/uc?export=view&id=17p2PRsa0obNrcw6wHuv2OJh7SsVN543Y\">\n",
    "\n",
    "## Higher order distances (Ln standard)\n",
    "\n",
    "Higher order distances can be calculated using a formula such as:\n",
    "\n",
    "<img alt=\"Higher Order\" src=\"https://drive.google.com/uc?export=view&id=1OK06w3U9mV2VZ37yD7V3AraiDOW6UNky\">\n",
    "\n",
    "In the figure opposite, an illustration of the \"unit circle\" is shown for the different distances, at infinity the distance becomes:\n",
    "\n",
    "<img alt=\"\" src=\"https://drive.google.com/uc?export=view&id=1Vj4Vaea3ILHwTEHBLIgJTkPo8F6A6qw_\">\n",
    "\n",
    "The higher the order, the more the distance favours large distances over small distances. Two points whose coordinates are moderately close can therefore be considered closer than two points whose coordinates are identical except for one coordinate that is significantly different.\n",
    "\n",
    "\n",
    "<img alt=\"\" src=\"https://drive.google.com/uc?export=view&id=1yw6BBG1WFLKo9CXi6swpAD06gflGSg_n\">\n",
    "\n",
    "\n",
    "## Word distance \n",
    "\n",
    "If we compare two \"words\" with each other we can calculate the distance the following way by going through the word character by character:\n",
    "\n",
    "\n",
    "*  If the two characters are identical, we add a distance of `0`.\n",
    "\n",
    "*  If the two characters are different, we add a distance of `1`.\n",
    "\n",
    "*  If we observe a character in one word and the next character is seperated by a space, we add a distance of `2`.\n",
    "\n",
    "This distance is called the Levenshtein distance and considers that the distance between two words is quantified by the number of changes that need to be made to move from one to the other as shown in the example opposite.\n",
    "\n",
    "<img alt=\"\" src=\"https://drive.google.com/uc?export=view&id=1k6llyD6I7tny6UyJokoiLciyVgWSiTju\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources üìöüìö\n",
    "\n",
    "10 usecases of KMeans - [https://bit.ly/Yh2](https://dzone.com/articles/10-interesting-use-cases-for-the-k-means-algorithm)\n",
    "\n",
    "KMeans clustering for classification - [https://bit.ly/Hji](https://towardsdatascience.com/kmeans-clustering-for-classification-74b992405d0a)\n",
    "\n",
    "Understanding KMeans clustering - [https://bit.ly/3hA](https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1)\n",
    "\n",
    "So you have some clusters, Now what ? - [https://bit.ly/24Ah](https://medium.com/square-corner-blog/so-you-have-some-clusters-now-what-abfd297a575b)\n",
    "\n",
    "In Depth: KMeans clustering - [https://jed.ha/Z3a](https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
