{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01-Manipulate_data_with_tensorflow.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZNW5K_m7t8Tu"},"source":["# Manipulate data with tensorflow\r\n","\r\n","In this exercise you will practice manipulating tensors and forming tensor datasets with tensorflow.\r\n","We are taking advantage of this moment to let you only manipulate data as we will be focusing much more on building models in the following days!"]},{"cell_type":"code","metadata":{"id":"Awl5S3siIE2I","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1615631044495,"user_tz":-60,"elapsed":2172,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"1446b04c-462a-4369-b202-e4057f3b5be1"},"source":["# import tensorflow\r\n","import tensorflow as tf\r\n","tf.__version__"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.4.1'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"be1UHQRtufib"},"source":["## Practice tensor operations\r\n","\r\n","* Create a **constant tensor** named `tensor1` containing the values `[0, 1, 2, 3, 4, 5, 6, 7]` and a **variable tensor** named `tensor2` containing the values `[0, 1, 2, 0, 1, 2]`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bC8EkoJRt1YT","executionInfo":{"status":"ok","timestamp":1615631237553,"user_tz":-60,"elapsed":526,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"0a1e09a4-00b7-4a27-c940-bcd43629bbde"},"source":["tensor1 = tf.constant([0, 1, 2, 3, 4, 5, 6, 7])\n","print(\"tensor1:\", tensor1)\n","tensor2 = tf.Variable([0, 1, 2, 0, 1, 2])\n","print(\"tensor2:\", tensor2)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["tensor1: tf.Tensor([0 1 2 3 4 5 6 7], shape=(8,), dtype=int32)\n","tensor2: <tf.Variable 'Variable:0' shape=(6,) dtype=int32, numpy=array([0, 1, 2, 0, 1, 2], dtype=int32)>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8kZZuF9FIRPp"},"source":["* Reshape `tensor1` so it has 2 columns and 4 rows, and `tensor2` so it has 2 rows and 3 columns.\r\n","Has this operation changed the nature of `tensor2`? How could you change it back to its former nature?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"weoWXp-tIQB9","executionInfo":{"status":"ok","timestamp":1615631241713,"user_tz":-60,"elapsed":457,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"2684b20b-4398-4b43-95b5-684f0a9b4765"},"source":["tensor1 = tf.reshape(tensor1, (4,2))\r\n","print(\"tensor1:\", tensor1)\r\n","tensor2 = tf.reshape(tensor2, (2, 3))\r\n","print(\"tensor2:\", tensor2)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["tensor1: tf.Tensor(\n","[[0 1]\n"," [2 3]\n"," [4 5]\n"," [6 7]], shape=(4, 2), dtype=int32)\n","tensor2: tf.Tensor(\n","[[0 1 2]\n"," [0 1 2]], shape=(2, 3), dtype=int32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LM5T5YDFKPKy","executionInfo":{"status":"ok","timestamp":1615631296257,"user_tz":-60,"elapsed":453,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"0b533bf9-5ef2-4aae-dc1f-33442b39dec2"},"source":["tensor2 = tf.Variable(tensor2)\r\n","print(\"tensor2:\", tensor2)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["tensor2: <tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n","array([[0, 1, 2],\n","       [0, 1, 2]], dtype=int32)>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A9t1o_2FI8gM"},"source":["* Use a tensorflow function to create `tensor3` with the same shape as `tensor2` but filled with 1"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gfdyLooDJMmI","executionInfo":{"status":"ok","timestamp":1615631556788,"user_tz":-60,"elapsed":500,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"f30e8800-3bc1-4672-dce9-d8b341789094"},"source":["tensor3 = tf.ones_like(tensor2)\r\n","print(\"tensor2:\", tensor3)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["tensor2: tf.Tensor(\n","[[1 1 1]\n"," [1 1 1]], shape=(2, 3), dtype=int32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D-cHLAq6JYB8"},"source":["* Modify the value of `tensor2` by substracting the values in `tensor3`, use a method so that it is an in place operation. Why would not you be able to do that with `tensor1`?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g1tpdjDdJfcP","executionInfo":{"status":"ok","timestamp":1615631806010,"user_tz":-60,"elapsed":472,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"6a6b916d-97e3-4db0-caf0-37301d4fc95f"},"source":["tensor2.assign_sub(tensor3)\r\n","print(\"tensor2:\", tensor2)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["tensor2: <tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n","array([[-1,  0,  1],\n","       [-1,  0,  1]], dtype=int32)>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f0CzXqjyKqpF"},"source":["* Can you multiply `tensor1` and `tensor2` pointwise? How about with a matrix multiplication? Display the result of the possible operations."]},{"cell_type":"code","metadata":{"id":"_0qoTJUwt2CD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615632261734,"user_tz":-60,"elapsed":468,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"a4a52783-f80e-47dd-8e03-0e2a4c42ca7b"},"source":["tf.matmul(tensor1, tensor2)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n","array([[ -1,   0,   1],\n","       [ -5,   0,   5],\n","       [ -9,   0,   9],\n","       [-13,   0,  13]], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"BKMIyxcnt42G","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"error","timestamp":1615632286122,"user_tz":-60,"elapsed":607,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"a478f511-7a2d-447d-f9da-3ef95c9df417"},"source":["tensor1 * tensor2"],"execution_count":13,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-bbd0b9179ca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensor1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    516\u001b[0m   \"\"\"\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6066\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6067\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6068\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6069\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6070\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [4,2] vs. [2,3] [Op:Mul]"]}]},{"cell_type":"markdown","metadata":{"id":"l_Flhy7uLS7w"},"source":["## Tabular data\r\n","\r\n","This part of the exercise will let you deal with tabular data in order to make batch datasets ready to be fed to deep learning models.\r\n","\r\n","* Using the `sklearn.datasets` module, load the mnist dataset thanks to the `load_digits` function."]},{"cell_type":"code","metadata":{"id":"e3VytM5ALuCo","executionInfo":{"status":"ok","timestamp":1615632431304,"user_tz":-60,"elapsed":485,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}}},"source":["from sklearn.datasets import load_digits"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EO54ZELkMDnI"},"source":["* This function gives you a Data Bunch object, which works basically like a dictionnary. Create an object data containing the value of the `data` key and an object target containing the value of the `target` key."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oE8RzXi6MBOk","executionInfo":{"status":"ok","timestamp":1615634638788,"user_tz":-60,"elapsed":512,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"c4dba1c2-ee6e-4453-dbd7-663dc2e7394c"},"source":["data, target = load_digits(return_X_y=True)\r\n","\r\n","print(data)\r\n","print(target)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["[[ 0.  0.  5. ...  0.  0.  0.]\n"," [ 0.  0.  0. ... 10.  0.  0.]\n"," [ 0.  0.  0. ... 16.  9.  0.]\n"," ...\n"," [ 0.  0.  1. ...  6.  0.  0.]\n"," [ 0.  0.  2. ... 12.  0.  0.]\n"," [ 0.  0. 10. ... 12.  1.  0.]]\n","[0 1 2 ... 8 9 8]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RoyvPr2sNGxt"},"source":["* What is the shape of `data` and `target`? Can you understand what these objects represent using the `DESCR` key of the Data Bunch?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kOGvg9jcNV5N","executionInfo":{"status":"ok","timestamp":1615634647914,"user_tz":-60,"elapsed":483,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"6b2fc7e9-8c94-4b54-fec7-f5d5b26ace49"},"source":["print(f\"data shape: {data.shape}\")\r\n","print(f\"target shape: {target.shape}\")\r\n","print(load_digits().DESCR)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["data shape: (1797, 64)\n","target shape: (1797,)\n",".. _digits_dataset:\n","\n","Optical recognition of handwritten digits dataset\n","--------------------------------------------------\n","\n","**Data Set Characteristics:**\n","\n","    :Number of Instances: 5620\n","    :Number of Attributes: 64\n","    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n","    :Missing Attribute Values: None\n","    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n","    :Date: July; 1998\n","\n","This is a copy of the test set of the UCI ML hand-written digits datasets\n","https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n","\n","The data set contains images of hand-written digits: 10 classes where\n","each class refers to a digit.\n","\n","Preprocessing programs made available by NIST were used to extract\n","normalized bitmaps of handwritten digits from a preprinted form. From a\n","total of 43 people, 30 contributed to the training set and different 13\n","to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n","4x4 and the number of on pixels are counted in each block. This generates\n","an input matrix of 8x8 where each element is an integer in the range\n","0..16. This reduces dimensionality and gives invariance to small\n","distortions.\n","\n","For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n","T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n","L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n","1994.\n","\n",".. topic:: References\n","\n","  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n","    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n","    Graduate Studies in Science and Engineering, Bogazici University.\n","  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n","  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n","    Linear dimensionalityreduction using relevance weighted LDA. School of\n","    Electrical and Electronic Engineering Nanyang Technological University.\n","    2005.\n","  - Claudio Gentile. A New Approximate Maximal Margin Classification\n","    Algorithm. NIPS. 2000.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LgrbbCLSORpb"},"source":["* Can you visualize the first image in data ?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"Fo0OnrB2OMcz","executionInfo":{"status":"ok","timestamp":1615634663717,"user_tz":-60,"elapsed":469,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"13937a4f-4ed0-4e2c-fa5f-528089c5906d"},"source":["from matplotlib import pyplot as plt\r\n","\r\n","plt.imshow(data[0, :].reshape(8, 8))\r\n","plt.show()"],"execution_count":43,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"x3TwGhRPacK0"},"source":["* The pixel values from those images is encoded in integers between 0 and 255, it is always better to feed your deep learning models with reasonnably scaled data to avoid the network not being able to learn. To do this we'll divide the value in each pixel by 255. Do this."]},{"cell_type":"code","metadata":{"id":"zazDEYPiaak8","executionInfo":{"status":"ok","timestamp":1615634667266,"user_tz":-60,"elapsed":479,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}}},"source":["data /= 255"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tPVqElsAXHTt"},"source":["### Technique 1: Split the data with sklearn\r\n","\r\n","Most of the time when you will be dealing with data you want to feed to a deap learning model, you will have a pandas DataFrame or numpy array at some points that contains some representation of your data and the associated values of the target variable. In those cases, it's easier to just split the data in a train and validation set using sklearn. (Remember that for very large datasets or for training and evaluating deep learning models we most of the time use the three way hold out method, where on set serves as the training set, one as the validation set to control for overfitting, and the last one is the test set against which we will evaluate the model).\r\n","\r\n","* Split the data and target into three different parts, one containing the train set (60%), another with the validation set (20%), and a third with the test set (20%), using sklearn."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VBPDWY2OXFsd","executionInfo":{"status":"ok","timestamp":1615634680327,"user_tz":-60,"elapsed":452,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"25a41977-6362-46ec-d22e-a4177633747d"},"source":["from sklearn.model_selection import train_test_split\r\n","\r\n","X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=0)\r\n","\r\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0) \r\n","\r\n","print(f\"X train : {X_train.shape}\")\r\n","print(f\"X val : {X_val.shape}\")\r\n","print(f\"X test : {X_test.shape}\")\r\n","print(f\"y train : {y_train.shape}\")\r\n","print(f\"y val : {y_val.shape}\")\r\n","print(f\"y test : {y_test.shape}\")\r\n"],"execution_count":45,"outputs":[{"output_type":"stream","text":["X train : (1077, 64)\n","X val : (360, 64)\n","X test : (360, 64)\n","y train : (1077,)\n","y val : (360,)\n","y test : (360,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FzugIQTQZOUn"},"source":["* Form three tensor slice datasets using the training validation and test data."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHWr5HfCZKLb","executionInfo":{"status":"ok","timestamp":1615633900820,"user_tz":-60,"elapsed":451,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"443681b2-06b6-4e5e-e3c0-9e7fa86cff93"},"source":["train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\r\n","val = tf.data.Dataset.from_tensor_slices((X_val, y_val))\r\n","test = tf.data.Dataset.from_tensor_slices((X_test, y_test))\r\n","print(f\"train : {train}\")\r\n","print(f\"val : {val}\")\r\n","print(f\"test : {test}\")"],"execution_count":35,"outputs":[{"output_type":"stream","text":["train : <TensorSliceDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)>\n","val : <TensorSliceDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)>\n","test : <TensorSliceDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7ft2lVP5ZraP"},"source":["* Shuffle these tensor slice datasets and arrange them in batches of 8 observations, then display one batch from each of these batch datasets."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r6upGSBPZ6TY","executionInfo":{"status":"ok","timestamp":1615634492335,"user_tz":-60,"elapsed":1176,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"01c9d0cc-0e5d-46a6-ea03-831c7b6319fe"},"source":["train_batch = train.shuffle(len(X_train)).batch(8)\r\n","val_batch = val.shuffle(len(X_val)).batch(8)\r\n","test_batch = test.shuffle(len(X_test)).batch(8)\r\n","\r\n","x, y = next(iter(train_batch))\r\n","print(\"train batch shape\", x.shape, y.shape)\r\n","x, y = next(iter(val_batch))\r\n","print(\"val batch\", x.shape, y.shape)\r\n","x, y = next(iter(test_batch))\r\n","print(\"test batch\", x.shape, y.shape)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["train batch shape (8, 64) (8,)\n","val batch (8, 64) (8,)\n","test batch (8, 64) (8,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AIG8SZ_fbAM4"},"source":["We are now ready to start training deep learning models!"]},{"cell_type":"markdown","metadata":{"id":"fhAb3OHwbFHh"},"source":["## Technique 2: split using tensorflow\r\n","\r\n","This technique is not so recommended because tensorflow is not able to work with datasets in the same way that sklearn does, it is not as practical to split the data in a random way, but we will show you how it can be done, as sometimes you will strictly be working with tensorflow objects.\r\n","\r\n","* Create a tensor slice dataset object using `data`and `target`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kdlzq88sa5tr","executionInfo":{"status":"ok","timestamp":1615634691522,"user_tz":-60,"elapsed":464,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"1c0360aa-464c-4a3f-917d-cfdfbf543832"},"source":["full_ds = tf.data.Dataset.from_tensor_slices((data, target))\r\n","print(\"full_ds\", full_ds)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["full_ds <TensorSliceDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iLDSGNPIbvMn"},"source":["* Using the commands take and skip, separate the tensor slice dataset into a train object containing 60% of the data, a val object (20%) and a test object (20%)."]},{"cell_type":"code","metadata":{"id":"NvTEUACTbuSb","executionInfo":{"status":"ok","timestamp":1615635568508,"user_tz":-60,"elapsed":465,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}}},"source":["n_observations = len(data)\r\n","n_train = int(0.6 * n_observations)\r\n","n_val = int(0.5 * (n_observations - n_train))\r\n","n_test = n_observations - n_train - n_val\r\n","\r\n","shuffle_full_ds = full_ds.shuffle(len(data))\r\n","train = shuffle_full_ds.take(n_train)\r\n","val = shuffle_full_ds.skip(n_train).take(n_val)\r\n","test = shuffle_full_ds.skip(n_train + n_val).take(n_test)"],"execution_count":54,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TTdWCH3ic7Dm"},"source":["* Use methods shuffle and batch in order to create batch datasets with batches of 8 observations for train, val, and test, and show one batch from each of these objects."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ghhNRALRdGLy","executionInfo":{"status":"ok","timestamp":1615635598529,"user_tz":-60,"elapsed":475,"user":{"displayName":"Thibaud Chevrier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5z4SprdZvSXM4zmX6KlR00byF7TSJnd4-ZC6g-rc=s64","userId":"07612137038061989735"}},"outputId":"f46bf582-6778-4e29-8e34-6300f95a5893"},"source":["train_batch = train.shuffle(len(X_train)).batch(8)\r\n","val_batch = val.shuffle(len(X_val)).batch(8)\r\n","test_batch = test.shuffle(len(X_test)).batch(8)\r\n","\r\n","x, y = next(iter(train_batch))\r\n","print(\"train batch shape\", x.shape, y.shape)\r\n","x, y = next(iter(val_batch))\r\n","print(\"val batch\", x.shape, y.shape)\r\n","x, y = next(iter(test_batch))\r\n","print(\"test batch\", x.shape, y.shape)"],"execution_count":55,"outputs":[{"output_type":"stream","text":["train batch shape (8, 64) (8,)\n","val batch (8, 64) (8,)\n","test batch (8, 64) (8,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6fUS1ootddPP"},"source":["Congratulations, you know two different ways of forming datasets that are fit for training deep learning models with tensorflow! This skill will come in very handy as we will try to focus more on building models from now on, and put less focus on preprocessing.\r\n","Until then, happy learning!"]}]}